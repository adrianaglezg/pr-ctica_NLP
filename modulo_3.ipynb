{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>created_timestamp</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>author_created_utc</th>\n",
       "      <th>full_link</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>post</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-11 19:47:22</td>\n",
       "      <td>1265910442.0</td>\n",
       "      <td>analytics</td>\n",
       "      <td>So what do you guys all do related to analytic...</td>\n",
       "      <td>xtom</td>\n",
       "      <td>1.227476e+09</td>\n",
       "      <td>https://www.reddit.com/r/analytics/comments/b0...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's a lot of reasons to want to know all t...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>theres lot reasons want know stuff figured id ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-03-04 20:17:26</td>\n",
       "      <td>1267726646.0</td>\n",
       "      <td>analytics</td>\n",
       "      <td>Google's Invasive, non-Anonymized Ad Targeting...</td>\n",
       "      <td>xtom</td>\n",
       "      <td>1.227476e+09</td>\n",
       "      <td>https://www.reddit.com/r/analytics/comments/b9...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm cross posting this from /r/cyberlaw, hopef...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>im cross posting rcyberlaw hopefully guys find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-06 04:51:18</td>\n",
       "      <td>1294282278.0</td>\n",
       "      <td>analytics</td>\n",
       "      <td>DotCed - Functional Web Analytics - Tagging, R...</td>\n",
       "      <td>dotced</td>\n",
       "      <td>1.294282e+09</td>\n",
       "      <td>https://www.reddit.com/r/analytics/comments/ew...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DotCed,a Functional Analytics Consultant, offe...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>dotceda functional analytics consultant offeri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-19 11:45:30</td>\n",
       "      <td>1295430330.0</td>\n",
       "      <td>analytics</td>\n",
       "      <td>Program Details - Data Analytics Course</td>\n",
       "      <td>iqrconsulting</td>\n",
       "      <td>1.288245e+09</td>\n",
       "      <td>https://www.reddit.com/r/analytics/comments/f5...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Here is the program details of the data analyt...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>program details data analytics certification c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-19 21:52:28</td>\n",
       "      <td>1295466748.0</td>\n",
       "      <td>analytics</td>\n",
       "      <td>potential job in web analytics... need to anal...</td>\n",
       "      <td>therewontberiots</td>\n",
       "      <td>1.278672e+09</td>\n",
       "      <td>https://www.reddit.com/r/analytics/comments/f5...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i decided grad school (physics) was not for me...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>decided grad school physics branching job mark...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          created_date created_timestamp  subreddit  \\\n",
       "0  2010-02-11 19:47:22      1265910442.0  analytics   \n",
       "1  2010-03-04 20:17:26      1267726646.0  analytics   \n",
       "2  2011-01-06 04:51:18      1294282278.0  analytics   \n",
       "3  2011-01-19 11:45:30      1295430330.0  analytics   \n",
       "4  2011-01-19 21:52:28      1295466748.0  analytics   \n",
       "\n",
       "                                               title            author  \\\n",
       "0  So what do you guys all do related to analytic...              xtom   \n",
       "1  Google's Invasive, non-Anonymized Ad Targeting...              xtom   \n",
       "2  DotCed - Functional Web Analytics - Tagging, R...            dotced   \n",
       "3            Program Details - Data Analytics Course     iqrconsulting   \n",
       "4  potential job in web analytics... need to anal...  therewontberiots   \n",
       "\n",
       "   author_created_utc                                          full_link  \\\n",
       "0        1.227476e+09  https://www.reddit.com/r/analytics/comments/b0...   \n",
       "1        1.227476e+09  https://www.reddit.com/r/analytics/comments/b9...   \n",
       "2        1.294282e+09  https://www.reddit.com/r/analytics/comments/ew...   \n",
       "3        1.288245e+09  https://www.reddit.com/r/analytics/comments/f5...   \n",
       "4        1.278672e+09  https://www.reddit.com/r/analytics/comments/f5...   \n",
       "\n",
       "   score  num_comments  num_crossposts  subreddit_subscribers  \\\n",
       "0    7.0           4.0             0.0                    NaN   \n",
       "1    2.0           1.0             0.0                    NaN   \n",
       "2    1.0           1.0             NaN                    NaN   \n",
       "3    0.0           0.0             NaN                    NaN   \n",
       "4    2.0           4.0             NaN                    NaN   \n",
       "\n",
       "                                                post sentiment  \\\n",
       "0  There's a lot of reasons to want to know all t...  NEGATIVE   \n",
       "1  I'm cross posting this from /r/cyberlaw, hopef...  NEGATIVE   \n",
       "2  DotCed,a Functional Analytics Consultant, offe...  NEGATIVE   \n",
       "3  Here is the program details of the data analyt...  NEGATIVE   \n",
       "4  i decided grad school (physics) was not for me...  POSITIVE   \n",
       "\n",
       "                                          clean_post  \n",
       "0  theres lot reasons want know stuff figured id ...  \n",
       "1  im cross posting rcyberlaw hopefully guys find...  \n",
       "2  dotceda functional analytics consultant offeri...  \n",
       "3  program details data analytics certification c...  \n",
       "4  decided grad school physics branching job mark...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'processed_dataset.csv'\n",
    "df = pd.read_csv(path,\n",
    "                 low_memory=False) \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subreddit_mentions(text: str) -> list:\n",
    "    '''\n",
    "    Extract all subreddit mentions in a given text.\n",
    "    It searches for patterns like '/r/subreddit'.\n",
    "\n",
    "    Input:\n",
    "    - text (str): The input text to search for subreddit mentions.\n",
    "\n",
    "    Output:\n",
    "    - list: A list containing the mentioned subreddits.\n",
    "    '''\n",
    "    \n",
    "    pattern = r'/r/\\w+'\n",
    "    \n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/r/cyberlaw', '/r/MachineLearning']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I'm cross posting this from /r/cyberlaw and also sharing it to /r/MachineLearning.\"\n",
    "result = find_subreddit_mentions(text)\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>subreddit_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201222</th>\n",
       "      <td>Bit of a dumb question but here I go:\\n\\nI re...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89485</th>\n",
       "      <td># We're building a learning platform that adap...</td>\n",
       "      <td>[/r/learnmachinelearning, /r/learnmachinelearn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33584</th>\n",
       "      <td>I used to be a video editor for this internet ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77335</th>\n",
       "      <td># [OC] Beginner Machine Learning Algorithms - ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170885</th>\n",
       "      <td>In order to better understand the human body f...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20037</th>\n",
       "      <td>Hey guys,\\n\\nCross posted from /r/bioinformati...</td>\n",
       "      <td>[/r/bioinformatics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213841</th>\n",
       "      <td>I am currently thinking about my IB Computer S...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264348</th>\n",
       "      <td>I have some data that records the number and r...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81844</th>\n",
       "      <td>Sentiment analysis is the technique of analyzi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272789</th>\n",
       "      <td>Hello,\\n\\nI'm trying to analyse data from a pr...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110339</th>\n",
       "      <td>https://www.datasciencecentral.com/profiles/bl...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224285</th>\n",
       "      <td>I've been toying with using browser fingerprin...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236122</th>\n",
       "      <td>I graduated with a bachelors degree in busines...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88452</th>\n",
       "      <td>In order to augment data for the NLP project, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123063</th>\n",
       "      <td>This video talks about how Machine Learning is...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204839</th>\n",
       "      <td>TLDR (I know no one likes reading): Bought a d...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140174</th>\n",
       "      <td>In Blei's 2003 paper **Latent Dirichlet Alloca...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163266</th>\n",
       "      <td>Hi folks,\\n\\nThis is likely a dumb question bu...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89140</th>\n",
       "      <td>I want to further my MLand stats knowledge. Co...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249434</th>\n",
       "      <td>*This movie is very good, the best link in aug...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  \\\n",
       "201222   Bit of a dumb question but here I go:\\n\\nI re...   \n",
       "89485   # We're building a learning platform that adap...   \n",
       "33584   I used to be a video editor for this internet ...   \n",
       "77335   # [OC] Beginner Machine Learning Algorithms - ...   \n",
       "170885  In order to better understand the human body f...   \n",
       "20037   Hey guys,\\n\\nCross posted from /r/bioinformati...   \n",
       "213841  I am currently thinking about my IB Computer S...   \n",
       "264348  I have some data that records the number and r...   \n",
       "81844   Sentiment analysis is the technique of analyzi...   \n",
       "272789  Hello,\\n\\nI'm trying to analyse data from a pr...   \n",
       "110339  https://www.datasciencecentral.com/profiles/bl...   \n",
       "224285  I've been toying with using browser fingerprin...   \n",
       "236122  I graduated with a bachelors degree in busines...   \n",
       "88452   In order to augment data for the NLP project, ...   \n",
       "123063  This video talks about how Machine Learning is...   \n",
       "204839  TLDR (I know no one likes reading): Bought a d...   \n",
       "140174  In Blei's 2003 paper **Latent Dirichlet Alloca...   \n",
       "163266  Hi folks,\\n\\nThis is likely a dumb question bu...   \n",
       "89140   I want to further my MLand stats knowledge. Co...   \n",
       "249434  *This movie is very good, the best link in aug...   \n",
       "\n",
       "                                       subreddit_mentions  \n",
       "201222                                                 []  \n",
       "89485   [/r/learnmachinelearning, /r/learnmachinelearn...  \n",
       "33584                                                  []  \n",
       "77335                                                  []  \n",
       "170885                                                 []  \n",
       "20037                                 [/r/bioinformatics]  \n",
       "213841                                                 []  \n",
       "264348                                                 []  \n",
       "81844                                                  []  \n",
       "272789                                                 []  \n",
       "110339                                                 []  \n",
       "224285                                                 []  \n",
       "236122                                                 []  \n",
       "88452                                                  []  \n",
       "123063                                                 []  \n",
       "204839                                                 []  \n",
       "140174                                                 []  \n",
       "163266                                                 []  \n",
       "89140                                                  []  \n",
       "249434                                                 []  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_rows = df.sample(n=20)\n",
    "random_rows['subreddit_mentions'] = random_rows['post'].apply(find_subreddit_mentions)\n",
    "\n",
    "random_rows[['post', 'subreddit_mentions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_extraction(text: str) -> list:\n",
    "    '''\n",
    "    Extract all URLs in a given text.\n",
    "    It searches for patterns that match common URL formats.\n",
    "\n",
    "    Input:\n",
    "    - text (str): The input text to search for URLs.\n",
    "\n",
    "    Output:\n",
    "    - list: A list containing all the extracted URLs.\n",
    "    '''\n",
    "    pattern = r'(https?://\\S+|www\\.\\S+)'\n",
    "    urls = re.findall(pattern, text)\n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://example.com/tutorial', 'www.datasciencehub.com']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Check this out: https://example.com/tutorial and also visit www.datasciencehub.com for more details.\"\n",
    "result = url_extraction(text)\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>extracted_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28260</th>\n",
       "      <td>When ML models need to be regularly updated in...</td>\n",
       "      <td>[https://medium.com/@christopher.samiullah/fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260514</th>\n",
       "      <td>I have a question about the approach to a deep...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240625</th>\n",
       "      <td>Martin is answering our questions! We've alrea...</td>\n",
       "      <td>[https://datatalks.club/books/20210308-designi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216073</th>\n",
       "      <td>Hey this may not be the right place, but I’ve ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64490</th>\n",
       "      <td>I am looking for datasets of QAR/QAD  for anal...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209104</th>\n",
       "      <td>So I am currently working on a computer scienc...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83766</th>\n",
       "      <td>Apologies if this is the wrong place to post t...</td>\n",
       "      <td>[https://imgur.com/a/55ijYT6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265424</th>\n",
       "      <td>I am working on an analysis of tweets, using t...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68420</th>\n",
       "      <td>I was looking at some conceptual machine learn...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173343</th>\n",
       "      <td>I am not quite sure about the difference betwe...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16740</th>\n",
       "      <td>I just tried to use OpenRefine and/or GoogleRe...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31331</th>\n",
       "      <td>Currently an international Science teacher (fo...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31962</th>\n",
       "      <td>I’ve started a blog to provide beginner-friend...</td>\n",
       "      <td>[www.datascienceoutlook.com).]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196724</th>\n",
       "      <td>In the NBA, if the probability of each team wi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107805</th>\n",
       "      <td>I do not know whether I should post it here or...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192196</th>\n",
       "      <td>I'm going to attend university next year and I...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125031</th>\n",
       "      <td>**Paper:** \"Neural Anisotropy Directions\" (202...</td>\n",
       "      <td>[https://arxiv.org/abs/2006.09717](https://arx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22447</th>\n",
       "      <td>Hello Reddit , \\nI'll try to make this brief w...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238060</th>\n",
       "      <td>I have a few different data points, like produ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101684</th>\n",
       "      <td>Hi Everyone, \\n\\nIf you are on this thread, th...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  \\\n",
       "28260   When ML models need to be regularly updated in...   \n",
       "260514  I have a question about the approach to a deep...   \n",
       "240625  Martin is answering our questions! We've alrea...   \n",
       "216073  Hey this may not be the right place, but I’ve ...   \n",
       "64490   I am looking for datasets of QAR/QAD  for anal...   \n",
       "209104  So I am currently working on a computer scienc...   \n",
       "83766   Apologies if this is the wrong place to post t...   \n",
       "265424  I am working on an analysis of tweets, using t...   \n",
       "68420   I was looking at some conceptual machine learn...   \n",
       "173343  I am not quite sure about the difference betwe...   \n",
       "16740   I just tried to use OpenRefine and/or GoogleRe...   \n",
       "31331   Currently an international Science teacher (fo...   \n",
       "31962   I’ve started a blog to provide beginner-friend...   \n",
       "196724  In the NBA, if the probability of each team wi...   \n",
       "107805  I do not know whether I should post it here or...   \n",
       "192196  I'm going to attend university next year and I...   \n",
       "125031  **Paper:** \"Neural Anisotropy Directions\" (202...   \n",
       "22447   Hello Reddit , \\nI'll try to make this brief w...   \n",
       "238060  I have a few different data points, like produ...   \n",
       "101684  Hi Everyone, \\n\\nIf you are on this thread, th...   \n",
       "\n",
       "                                           extracted_urls  \n",
       "28260   [https://medium.com/@christopher.samiullah/fir...  \n",
       "260514                                                 []  \n",
       "240625  [https://datatalks.club/books/20210308-designi...  \n",
       "216073                                                 []  \n",
       "64490                                                  []  \n",
       "209104                                                 []  \n",
       "83766                       [https://imgur.com/a/55ijYT6]  \n",
       "265424                                                 []  \n",
       "68420                                                  []  \n",
       "173343                                                 []  \n",
       "16740                                                  []  \n",
       "31331                                                  []  \n",
       "31962                      [www.datascienceoutlook.com).]  \n",
       "196724                                                 []  \n",
       "107805                                                 []  \n",
       "192196                                                 []  \n",
       "125031  [https://arxiv.org/abs/2006.09717](https://arx...  \n",
       "22447                                                  []  \n",
       "238060                                                 []  \n",
       "101684                                                 []  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_rows = df.sample(n=20)  \n",
    "random_rows['extracted_urls'] = random_rows['post'].apply(url_extraction)\n",
    "\n",
    "random_rows[['post', 'extracted_urls']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phone_number_extraction(text: str) -> list:\n",
    "    '''\n",
    "    Extract phone numbers from a given text.\n",
    "    It searches for patterns matching common phone number formats.\n",
    "\n",
    "    Input:\n",
    "    - text (str): The input text to search for phone numbers.\n",
    "\n",
    "    Output:\n",
    "    - list: A list containing all the extracted phone numbers.\n",
    "    '''\n",
    "    pattern = r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}'\n",
    "    phone_numbers = re.findall(pattern, text)\n",
    "    return phone_numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(123) 456-7890']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Call me at (123) 456-7890 for details.'\n",
    "result = phone_number_extraction(text)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>extracted_phone_numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110507</th>\n",
       "      <td>[https://icml.cc/Conferences/2019/AcceptedPape...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>So I'm testing out an implementation of Google...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140213</th>\n",
       "      <td>Thanks in advance.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150218</th>\n",
       "      <td>I’m tired of seeing the default reddit icon of...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71104</th>\n",
       "      <td>Hi r/learnmachinelearning\\n\\nI have a dataset ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135096</th>\n",
       "      <td>I'm having a somewhat brainless day apparently...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100059</th>\n",
       "      <td>Two very natural datasets that would seem to p...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254730</th>\n",
       "      <td>I know that perplexity is computed as two rais...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204313</th>\n",
       "      <td>Hello all! I'm a senior in high school and I w...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174716</th>\n",
       "      <td>Hello! \\n\\nI am running SPSS on multiple varia...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198022</th>\n",
       "      <td>In a hypothesis test for a single proportion ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70318</th>\n",
       "      <td>In https://stats385.github.io/assets/lectures/...</td>\n",
       "      <td>[385-2017102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49862</th>\n",
       "      <td>I'm currently finishing my undergraduate studi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48453</th>\n",
       "      <td>I've just finished my Bachelor's degree in Com...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195058</th>\n",
       "      <td>Okay, so that title was bad. \\n\\nI have built ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211798</th>\n",
       "      <td>So i literally just got my AA last week. So im...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79601</th>\n",
       "      <td>Hey everyone, I am new to the world of machine...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138787</th>\n",
       "      <td>Question not clear, have a look here:\\nhttp://...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9519</th>\n",
       "      <td>#voiceassistant \\n#keras \\n#tensorflow \\nAnyon...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258560</th>\n",
       "      <td>Hi, I've had this problem for awhile now. Afte...</td>\n",
       "      <td>[3633285889, 8484476804, 6187557253, 7472173571]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  \\\n",
       "110507  [https://icml.cc/Conferences/2019/AcceptedPape...   \n",
       "1422    So I'm testing out an implementation of Google...   \n",
       "140213                               Thanks in advance.     \n",
       "150218  I’m tired of seeing the default reddit icon of...   \n",
       "71104   Hi r/learnmachinelearning\\n\\nI have a dataset ...   \n",
       "135096  I'm having a somewhat brainless day apparently...   \n",
       "100059  Two very natural datasets that would seem to p...   \n",
       "254730  I know that perplexity is computed as two rais...   \n",
       "204313  Hello all! I'm a senior in high school and I w...   \n",
       "174716  Hello! \\n\\nI am running SPSS on multiple varia...   \n",
       "198022   In a hypothesis test for a single proportion ...   \n",
       "70318   In https://stats385.github.io/assets/lectures/...   \n",
       "49862   I'm currently finishing my undergraduate studi...   \n",
       "48453   I've just finished my Bachelor's degree in Com...   \n",
       "195058  Okay, so that title was bad. \\n\\nI have built ...   \n",
       "211798  So i literally just got my AA last week. So im...   \n",
       "79601   Hey everyone, I am new to the world of machine...   \n",
       "138787  Question not clear, have a look here:\\nhttp://...   \n",
       "9519    #voiceassistant \\n#keras \\n#tensorflow \\nAnyon...   \n",
       "258560  Hi, I've had this problem for awhile now. Afte...   \n",
       "\n",
       "                                 extracted_phone_numbers  \n",
       "110507                                                []  \n",
       "1422                                                  []  \n",
       "140213                                                []  \n",
       "150218                                                []  \n",
       "71104                                                 []  \n",
       "135096                                                []  \n",
       "100059                                                []  \n",
       "254730                                                []  \n",
       "204313                                                []  \n",
       "174716                                                []  \n",
       "198022                                                []  \n",
       "70318                                      [385-2017102]  \n",
       "49862                                                 []  \n",
       "48453                                                 []  \n",
       "195058                                                []  \n",
       "211798                                                []  \n",
       "79601                                                 []  \n",
       "138787                                                []  \n",
       "9519                                                  []  \n",
       "258560  [3633285889, 8484476804, 6187557253, 7472173571]  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_rows = df.sample(n=20)  \n",
    "random_rows['extracted_phone_numbers'] = random_rows['post'].apply(phone_number_extraction)\n",
    "\n",
    "random_rows[['post', 'extracted_phone_numbers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dates_extraction(text: str) -> list:\n",
    "    '''\n",
    "    Extract all dates from a given text.\n",
    "    It searches for patterns matching common date formats.\n",
    "\n",
    "    Input:\n",
    "    - text (str): The input text to search for dates.\n",
    "\n",
    "    Output:\n",
    "    - list: A list containing all the extracted dates.\n",
    "    '''\n",
    "    pattern = r'\\b(?:\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}|\\d{1,2}\\s\\w+\\s\\d{4}|\\w+\\s\\d{1,2},\\s\\d{4})\\b'\n",
    "    dates = re.findall(pattern, text)\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['January 1, 2023', '12/25/2023', '01-01-2024']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'See you on January 1, 2023, at the conference. Event on 12/25/2023 and another on 01-01-2024.'\n",
    "result = dates_extraction(text)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>extracted_dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22381</th>\n",
       "      <td>I've read mixed things on reddit about data sc...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96770</th>\n",
       "      <td>Does anyone have any great go-to resources for...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130582</th>\n",
       "      <td>Oftentimes I encounter operations that I do no...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47032</th>\n",
       "      <td>I recently got a job as a management trainee u...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73815</th>\n",
       "      <td>I did a course in Coursera (Andrew Ng),in whic...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83800</th>\n",
       "      <td>I'd like to extract some data from a paper fil...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185632</th>\n",
       "      <td>Sorry that this isn't  necessarily \"statistics...</td>\n",
       "      <td>[January 1, 2009, December 31, 2012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120738</th>\n",
       "      <td>I am getting started on this and want to build...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187786</th>\n",
       "      <td>\\n\\n&amp;gt;    New York City has been devastated...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174927</th>\n",
       "      <td>Hello people who can math better than I can! I...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153150</th>\n",
       "      <td>Hi everyone, I am working on a project to date...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133261</th>\n",
       "      <td>Please post your questions here instead of cre...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269352</th>\n",
       "      <td>Is there a good way to do this without changin...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33066</th>\n",
       "      <td>https://imgur.com/a/P5RyUT8\\n\\n\\n\\nCredit: htt...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149164</th>\n",
       "      <td>I’m looking to see whether system-justifying b...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64819</th>\n",
       "      <td>Need sample data for timekeeping. Specifically...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196177</th>\n",
       "      <td>Considering a random variable, with its pdf be...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156037</th>\n",
       "      <td>Has anyone ever tried applying cox proportiona...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9139</th>\n",
       "      <td>I implementation the paper StarGAN-VC Voice Co...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243919</th>\n",
       "      <td>Hi everyone,\\n\\nWe took inspiration from [Matt...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  \\\n",
       "22381   I've read mixed things on reddit about data sc...   \n",
       "96770   Does anyone have any great go-to resources for...   \n",
       "130582  Oftentimes I encounter operations that I do no...   \n",
       "47032   I recently got a job as a management trainee u...   \n",
       "73815   I did a course in Coursera (Andrew Ng),in whic...   \n",
       "83800   I'd like to extract some data from a paper fil...   \n",
       "185632  Sorry that this isn't  necessarily \"statistics...   \n",
       "120738  I am getting started on this and want to build...   \n",
       "187786   \\n\\n&gt;    New York City has been devastated...   \n",
       "174927  Hello people who can math better than I can! I...   \n",
       "153150  Hi everyone, I am working on a project to date...   \n",
       "133261  Please post your questions here instead of cre...   \n",
       "269352  Is there a good way to do this without changin...   \n",
       "33066   https://imgur.com/a/P5RyUT8\\n\\n\\n\\nCredit: htt...   \n",
       "149164  I’m looking to see whether system-justifying b...   \n",
       "64819   Need sample data for timekeeping. Specifically...   \n",
       "196177  Considering a random variable, with its pdf be...   \n",
       "156037  Has anyone ever tried applying cox proportiona...   \n",
       "9139    I implementation the paper StarGAN-VC Voice Co...   \n",
       "243919  Hi everyone,\\n\\nWe took inspiration from [Matt...   \n",
       "\n",
       "                             extracted_dates  \n",
       "22381                                     []  \n",
       "96770                                     []  \n",
       "130582                                    []  \n",
       "47032                                     []  \n",
       "73815                                     []  \n",
       "83800                                     []  \n",
       "185632  [January 1, 2009, December 31, 2012]  \n",
       "120738                                    []  \n",
       "187786                                    []  \n",
       "174927                                    []  \n",
       "153150                                    []  \n",
       "133261                                    []  \n",
       "269352                                    []  \n",
       "33066                                     []  \n",
       "149164                                    []  \n",
       "64819                                     []  \n",
       "196177                                    []  \n",
       "156037                                    []  \n",
       "9139                                      []  \n",
       "243919                                    []  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_rows = df.sample(n=20) \n",
    "random_rows['extracted_dates'] = random_rows['post'].apply(dates_extraction)\n",
    "\n",
    "random_rows[['post', 'extracted_dates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_extraction(text: str) -> list:\n",
    "    '''\n",
    "    Extract code snippets from a given text\n",
    "    It searches for:\n",
    "    - Blocks of code delimited by triple backticks\n",
    "    - Inline code delimited by single backticks\n",
    "    - HTML code tags\n",
    "    - Common programming patterns\n",
    "\n",
    "    Input:\n",
    "    - text (str): The input text to search for code snippets.\n",
    "\n",
    "    Outut:\n",
    "    - list: A list containing all the extracted code snippets.\n",
    "    '''\n",
    "    pattern = (\n",
    "        r'```[\\s\\S]*?```|'  \n",
    "        r'`[^`]+?`|' \n",
    "        r'<[^>]+>.*?</[^>]+>|'     \n",
    "        r'\\b(def\\s+\\w+\\(.*?\\):|'   # def()\n",
    "        r'print\\(.+?\\)|'           # print()\n",
    "        r'\\w+\\s*=\\s*\\[.*?\\])\\b'    #list []\n",
    "    )\n",
    "    \n",
    "    code_snippets = [match.group() for match in re.finditer(pattern, text)]\n",
    "    return code_snippets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<html><body>Hello</body>']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Check this code<html><body>Hello</body></html>\"\n",
    "resul = code_extraction(text)\n",
    "\n",
    "resul\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>extracted_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250696</th>\n",
       "      <td>If this is not the appropriate sub, I apologiz...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154729</th>\n",
       "      <td>Question on determining statistically signific...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196616</th>\n",
       "      <td>I'm faced with the example of an experiment wh...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50277</th>\n",
       "      <td>I ran a simple OLS regression and I would like...</td>\n",
       "      <td>[`estimates = sm.ols(formula='y ~ X).fit()`, `...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263688</th>\n",
       "      <td>Hello,\\n\\nIn my lab we are testing different c...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242804</th>\n",
       "      <td>Originally posted this in blind. I didnt get m...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262701</th>\n",
       "      <td>I am given a task to evaluate the the differen...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45333</th>\n",
       "      <td>Curious what is available from a commercial pe...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173487</th>\n",
       "      <td>Is the data presented here reasonsable?  I'm n...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249012</th>\n",
       "      <td>I have seen a few times statistics showing tha...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263289</th>\n",
       "      <td>I use Rstudio, but I've heard of several other...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140287</th>\n",
       "      <td>In a paper I read, they compared three groups ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232686</th>\n",
       "      <td>General pointers regarding clusternig of \"slic...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188206</th>\n",
       "      <td>Hello All,\\n\\nI have a peculiar question, for ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11274</th>\n",
       "      <td>We can do something good by using AI technolog...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262282</th>\n",
       "      <td>Pretty much the title. I know linear regressio...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168824</th>\n",
       "      <td>Professional translators (humans) will probabl...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73932</th>\n",
       "      <td>Performance function of a neural net is given ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240537</th>\n",
       "      <td>So i am going to do my Master’s in Data Analyt...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241551</th>\n",
       "      <td>[https://medium.com/paypal-tech/400-days-paypa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  \\\n",
       "250696  If this is not the appropriate sub, I apologiz...   \n",
       "154729  Question on determining statistically signific...   \n",
       "196616  I'm faced with the example of an experiment wh...   \n",
       "50277   I ran a simple OLS regression and I would like...   \n",
       "263688  Hello,\\n\\nIn my lab we are testing different c...   \n",
       "242804  Originally posted this in blind. I didnt get m...   \n",
       "262701  I am given a task to evaluate the the differen...   \n",
       "45333   Curious what is available from a commercial pe...   \n",
       "173487  Is the data presented here reasonsable?  I'm n...   \n",
       "249012  I have seen a few times statistics showing tha...   \n",
       "263289  I use Rstudio, but I've heard of several other...   \n",
       "140287  In a paper I read, they compared three groups ...   \n",
       "232686  General pointers regarding clusternig of \"slic...   \n",
       "188206  Hello All,\\n\\nI have a peculiar question, for ...   \n",
       "11274   We can do something good by using AI technolog...   \n",
       "262282  Pretty much the title. I know linear regressio...   \n",
       "168824  Professional translators (humans) will probabl...   \n",
       "73932   Performance function of a neural net is given ...   \n",
       "240537  So i am going to do my Master’s in Data Analyt...   \n",
       "241551  [https://medium.com/paypal-tech/400-days-paypa...   \n",
       "\n",
       "                                           extracted_code  \n",
       "250696                                                 []  \n",
       "154729                                                 []  \n",
       "196616                                                 []  \n",
       "50277   [`estimates = sm.ols(formula='y ~ X).fit()`, `...  \n",
       "263688                                                 []  \n",
       "242804                                                 []  \n",
       "262701                                                 []  \n",
       "45333                                                  []  \n",
       "173487                                                 []  \n",
       "249012                                                 []  \n",
       "263289                                                 []  \n",
       "140287                                                 []  \n",
       "232686                                                 []  \n",
       "188206                                                 []  \n",
       "11274                                                  []  \n",
       "262282                                                 []  \n",
       "168824                                                 []  \n",
       "73932                                                  []  \n",
       "240537                                                 []  \n",
       "241551                                                 []  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_rows = df.sample(n=20) \n",
    "random_rows['extracted_code'] = random_rows['post'].apply(code_extraction)\n",
    "\n",
    "random_rows[['post', 'extracted_code']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
