{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos todo lo que vamos a utilizar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "import emoji\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este módulo, realizaremos una función para que genere el resumen extractivo de un post de entrada basado en frecuencias. Para ello, tomaremos el post limpio como una cadena de texto y creamos un vector de conteo de su vocabulario mediante la aplicación de la técnica de Bag of Words. Una vez tengamos esto, para facilitar el análisis creamos un diccionario con el vocabulario y su frecuencia en la cadena de texto.\n",
    "La idea principal de este proceso es que las oraciones del resumen sean aquellas que tengan mayor valor. Este valor viene dado por la importancia de sus palabras, es decir, por la cantidad de veces que aparece sus palabras en todo el post. Por ello, para cada oración realizamos un contador al que iremos sumando la distribución de frecuencia de cada palabra de la oración. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>created_timestamp</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>author_created_utc</th>\n",
       "      <th>full_link</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>post</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-11 19:47:22</td>\n",
       "      <td>1265910442.0</td>\n",
       "      <td>analytics</td>\n",
       "      <td>So what do you guys all do related to analytic...</td>\n",
       "      <td>xtom</td>\n",
       "      <td>1.227476e+09</td>\n",
       "      <td>https://www.reddit.com/r/analytics/comments/b0...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's a lot of reasons to want to know all t...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-03-04 20:17:26</td>\n",
       "      <td>1267726646.0</td>\n",
       "      <td>analytics</td>\n",
       "      <td>Google's Invasive, non-Anonymized Ad Targeting...</td>\n",
       "      <td>xtom</td>\n",
       "      <td>1.227476e+09</td>\n",
       "      <td>https://www.reddit.com/r/analytics/comments/b9...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm cross posting this from /r/cyberlaw, hopef...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-06 04:51:18</td>\n",
       "      <td>1294282278.0</td>\n",
       "      <td>analytics</td>\n",
       "      <td>DotCed - Functional Web Analytics - Tagging, R...</td>\n",
       "      <td>dotced</td>\n",
       "      <td>1.294282e+09</td>\n",
       "      <td>https://www.reddit.com/r/analytics/comments/ew...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DotCed,a Functional Analytics Consultant, offe...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-19 11:45:30</td>\n",
       "      <td>1295430330.0</td>\n",
       "      <td>analytics</td>\n",
       "      <td>Program Details - Data Analytics Course</td>\n",
       "      <td>iqrconsulting</td>\n",
       "      <td>1.288245e+09</td>\n",
       "      <td>https://www.reddit.com/r/analytics/comments/f5...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Here is the program details of the data analyt...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-19 21:52:28</td>\n",
       "      <td>1295466748.0</td>\n",
       "      <td>analytics</td>\n",
       "      <td>potential job in web analytics... need to anal...</td>\n",
       "      <td>therewontberiots</td>\n",
       "      <td>1.278672e+09</td>\n",
       "      <td>https://www.reddit.com/r/analytics/comments/f5...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i decided grad school (physics) was not for me...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          created_date created_timestamp  subreddit  \\\n",
       "0  2010-02-11 19:47:22      1265910442.0  analytics   \n",
       "1  2010-03-04 20:17:26      1267726646.0  analytics   \n",
       "2  2011-01-06 04:51:18      1294282278.0  analytics   \n",
       "3  2011-01-19 11:45:30      1295430330.0  analytics   \n",
       "4  2011-01-19 21:52:28      1295466748.0  analytics   \n",
       "\n",
       "                                               title            author  \\\n",
       "0  So what do you guys all do related to analytic...              xtom   \n",
       "1  Google's Invasive, non-Anonymized Ad Targeting...              xtom   \n",
       "2  DotCed - Functional Web Analytics - Tagging, R...            dotced   \n",
       "3            Program Details - Data Analytics Course     iqrconsulting   \n",
       "4  potential job in web analytics... need to anal...  therewontberiots   \n",
       "\n",
       "   author_created_utc                                          full_link  \\\n",
       "0        1.227476e+09  https://www.reddit.com/r/analytics/comments/b0...   \n",
       "1        1.227476e+09  https://www.reddit.com/r/analytics/comments/b9...   \n",
       "2        1.294282e+09  https://www.reddit.com/r/analytics/comments/ew...   \n",
       "3        1.288245e+09  https://www.reddit.com/r/analytics/comments/f5...   \n",
       "4        1.278672e+09  https://www.reddit.com/r/analytics/comments/f5...   \n",
       "\n",
       "   score  num_comments  num_crossposts  subreddit_subscribers  \\\n",
       "0    7.0           4.0             0.0                    NaN   \n",
       "1    2.0           1.0             0.0                    NaN   \n",
       "2    1.0           1.0             NaN                    NaN   \n",
       "3    0.0           0.0             NaN                    NaN   \n",
       "4    2.0           4.0             NaN                    NaN   \n",
       "\n",
       "                                                post sentiment  \n",
       "0  There's a lot of reasons to want to know all t...  NEGATIVE  \n",
       "1  I'm cross posting this from /r/cyberlaw, hopef...  NEGATIVE  \n",
       "2  DotCed,a Functional Analytics Consultant, offe...  NEGATIVE  \n",
       "3  Here is the program details of the data analyt...  NEGATIVE  \n",
       "4  i decided grad school (physics) was not for me...  POSITIVE  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "dataframe = pd.read_csv('reddit_database_sentiment.csv', delimiter=';', low_memory=False)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la construcción de ese diccionario, vamos a comenzar limpiando un poco el texto con una función más simple que la que hemos hecho en el módulo 1. Una vez tengamos esto, aplicamos el vectorizador, extramos el vocabulario y su frecuencia y construimos el diccionario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras esto, tokenizamos por oraciones e iremos sumando el valor de cada palabra de la oración. Formaremos un diccionario oracion-suma total. Finalmente miraremos las oraciones con mayor puntuación. Esas serán las que compongan nuestro resumen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_summarisation(text:str):\n",
    "    \"\"\"Construcción del diccionario palabras-frecuencia\"\"\"\n",
    "    # Limpieza del texto\n",
    "    text_limpio = re.sub(r'\\[[0-9]*\\]', ' ', text)\n",
    "    text_limpio = re.sub(r'\\s+', ' ', text_limpio)\n",
    "    text_limpio = text_limpio.lower()\n",
    "    text_limpio = re.sub(r'\\d', ' ', text_limpio)\n",
    "    text_limpio = re.sub(r'\\s+', ' ', text_limpio)\n",
    "    text_limpio = re.sub(r'[^\\w\\s]', '', text_limpio)\n",
    "    \n",
    "    # Creación del diccionario (no tendremos en cuenta las stopwords)\n",
    "    vectorizador = CountVectorizer(stop_words=stopwords.words('english'))\n",
    "    frecuencias = vectorizador.fit_transform([text_limpio]) \n",
    "    vocabulario = list(vectorizador.vocabulary_.keys()) # Obtenemos el vocabulario\n",
    "    diccionario_palabras = dict(zip(vocabulario, frecuencias.sum(axis=0).A1))\n",
    "\n",
    "    \"\"\"Construcción del diccionario con el valor de cada oración\"\"\"\n",
    "    oraciones = sent_tokenize(text) # Segmentar el texto en oraciones\n",
    "    diccionario_oraciones = {} # Creación del diccionario vacío\n",
    "    for oracion in oraciones:\n",
    "        for palabra, freq in diccionario_palabras.items():\n",
    "            if palabra in oracion.lower():\n",
    "                if oracion in diccionario_oraciones.keys():\n",
    "                    diccionario_oraciones[oracion] += freq\n",
    "                else:\n",
    "                    diccionario_oraciones[oracion] = freq\n",
    "    \n",
    "    \"\"\"Obtenemos un cierto número de esas oraciones una vez ordenadas según su valor.\n",
    "       El número de oraciones será aleatorio entre 1 y el número de oraciones total.\"\"\"\n",
    "    oraciones_ordenadas = sorted(diccionario_oraciones, key=diccionario_oraciones.get, reverse=True)\n",
    "    oraciones_resumen = oraciones_ordenadas[:random.randint(1, len(oraciones))]\n",
    "    resumen = ' '.join(oraciones_resumen) # Devolvemos en forma de texto\n",
    "\n",
    "    \"\"\"Evaluación de la similitud entre el texto y el resumen generado\"\"\"\n",
    "    tfidf = TfidfVectorizer()\n",
    "    matriz = tfidf.fit_transform([text, resumen])\n",
    "    similitud = cosine_similarity(matriz)\n",
    "    return resumen, similitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto:  Greetings,\n",
      "\n",
      "I'm trying to configure GA for a business that uses \"yahoo small business\" hosting and store.  They use their own domain for the store, but when someone wants to check out, it moves domains to yahoo's servers.  Is it possible to track the cart in the same GA account? Right now we have no goals working. \n",
      "\n",
      "Do I need to make a separate account for yahoo's cart domain? It also changes from unsecured to secured during checkout, I'm not sure if this will affect the setup either.\n",
      "\n",
      "Thanks for any help guys!\n",
      "\n",
      "TLDR - http://www.store.com &gt; https://www.store.yahoo.net Wat do?\n",
      "\n",
      "Resumen: Greetings,\n",
      "\n",
      "I'm trying to configure GA for a business that uses \"yahoo small business\" hosting and store.\n",
      "Similitud: [[1.         0.97793952]\n",
      " [0.97793952 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print('Texto: ', dataframe.post[32])\n",
    "print()\n",
    "print('Resumen:', post_summarisation(dataframe.post[32])[0])\n",
    "print('Similitud:', post_summarisation(dataframe.post[32])[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
